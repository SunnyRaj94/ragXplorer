{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd57da10",
   "metadata": {},
   "source": [
    "#### ðŸ“Œ Goal: Compare different LLMs (OpenAI, Ollama, Together, Groq, etc.) for answering the same query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c701b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_utils.llm_integration import ask_openai, ask_ollama, ask_groq, ask_together\n",
    "from rag_utils.indexing import get_chroma_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71e6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… STEP 1: Get retriever\n",
    "chroma = get_chroma_collection(\"chroma_store\")\n",
    "\n",
    "query = \"Summarize the key ideas in the document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d62d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… STEP 2: Call LLMs\n",
    "print(\"ðŸ§  OpenAI:\")\n",
    "print(ask_openai(query, retriever=chroma))\n",
    "\n",
    "print(\"\\nðŸ§  Ollama:\")\n",
    "print(ask_ollama(query, retriever=chroma))\n",
    "\n",
    "print(\"\\nðŸ§  Groq:\")\n",
    "print(ask_groq(query, retriever=chroma))\n",
    "\n",
    "print(\"\\nðŸ§  Together AI:\")\n",
    "print(ask_together(query, retriever=chroma))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
